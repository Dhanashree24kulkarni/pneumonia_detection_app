# -*- coding: utf-8 -*-
"""pneumonia detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xz5vP7hSej9nw1FVLx1Fuw8XklF7FHeq
"""

# --- SINGLE-CELL PNEUMONIA DETECTION + TEST EVALUATION ---

# 1️⃣ Install & import packages
!pip install tensorflow matplotlib scikit-learn pillow kaggle

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix, classification_report
from google.colab import files
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import load_img, img_to_array

# 2️⃣ Upload kaggle.json
print("Upload your kaggle.json file")
uploaded = files.upload()

# 3️⃣ Configure Kaggle API
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# 4️⃣ Download & unzip dataset
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia
!unzip -q chest-xray-pneumonia.zip -d chest_xray

# 5️⃣ Paths
train_dir = '/content/chest_xray/chest_xray/train'
val_dir   = '/content/chest_xray/chest_xray/val'
test_dir  = '/content/chest_xray/chest_xray/test'
IMG_SIZE = (128,128)
BATCH_SIZE = 32

# 6️⃣ Image generators with stronger Normal augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    brightness_range=[0.7,1.3],
    shear_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_data = train_datagen.flow_from_directory(train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')
val_data = val_datagen.flow_from_directory(val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')
test_data = test_datagen.flow_from_directory(test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)

# 7️⃣ Compute class weights
y_train = train_data.classes
classes = np.unique(y_train)
class_weights = dict(enumerate(compute_class_weight('balanced', classes=classes, y=y_train)))
print("Class weights:", class_weights)

# 8️⃣ Build MobileNetV2 model, fine-tune last 40 layers
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128,128,3))
base_model.trainable = True
for layer in base_model.layers[:-40]:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
preds = Dense(1, activation='sigmoid')(x)
model = Model(base_model.input, preds)
model.compile(optimizer=RMSprop(1e-5), loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# 9️⃣ Callbacks
checkpoint = ModelCheckpoint("pneumonia_singlecell.keras", monitor='val_loss', save_best_only=True)
earlystop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# 10️⃣ Train model
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=15,
    class_weight=class_weights,
    callbacks=[checkpoint, earlystop]
)

# 11️⃣ Plot training history
plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs"); plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy")
plt.legend(); plt.show()

plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs"); plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend(); plt.show()

# 12️⃣ Load best saved model
model = load_model("pneumonia_singlecell.keras")

# 13️⃣ Evaluate on test set
loss, acc = model.evaluate(test_data)
print(f"\nTest Loss: {loss:.3f}, Test Accuracy: {acc:.3f}")

# 14️⃣ Predict all test images
preds = model.predict(test_data)
threshold = 0.75
pred_labels = (preds > threshold).astype(int)
true_labels = test_data.classes

# 15️⃣ Confusion matrix & classification report
cm = confusion_matrix(true_labels, pred_labels)
print("\nConfusion Matrix:\n", cm)

print("\nClassification Report:\n", classification_report(true_labels, pred_labels, target_names=['NORMAL','PNEUMONIA']))